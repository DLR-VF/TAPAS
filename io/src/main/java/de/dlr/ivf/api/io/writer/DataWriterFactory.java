package de.dlr.ivf.api.io.writer;

import de.dlr.ivf.api.io.configuration.model.DataSource;
import de.dlr.ivf.api.io.conversion.ColumnToFieldMapping;
import de.dlr.ivf.api.io.conversion.JavaToSqlTypeConverter;
import de.dlr.ivf.api.io.writer.implementation.IdReturningSimpleJdbcWriter;
import de.dlr.ivf.api.io.writer.implementation.JdbcBatchWriter;
import de.dlr.ivf.api.io.writer.implementation.PreparedStatementContext;
import de.dlr.ivf.api.io.writer.implementation.SimpleJdbcWriter;

import java.beans.IntrospectionException;
import java.beans.Introspector;
import java.beans.PropertyDescriptor;
import java.lang.reflect.Field;
import java.lang.reflect.Method;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.util.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Supplier;
import java.util.stream.Collectors;

public class DataWriterFactory {

    public static <S> DataWriter<S,Void> newJdbcBatchWriter(DataSource dataSource, Supplier<Connection>  connectionSupplier, Class<S> objectType) {

        PreparedStatementContext psContext = generatePsInvocationMethods(objectType, dataSource);

        Connection connection = connectionSupplier.get();

        PreparedStatement preparedStatement;
        try {
             preparedStatement = connection.prepareStatement(psContext.getQuery());
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
        return JdbcBatchWriter.<S>builder()
                .batchSize(1000)
                .connection(connection)
                .preparedStatement(preparedStatement)
                .psIndexToMethodMap(psContext.getMethods())
                .typeConverter(new JavaToSqlTypeConverter())
                .build();
    }

    public static <S> DataWriter<S,Void> newReusableJdbcWriter(DataSource dataSource, Supplier<Connection>  connectionSupplier, Class<S> objectType){

        PreparedStatementContext psContext = generatePsInvocationMethods(objectType, dataSource);

        return SimpleJdbcWriter.<S>builder()
                .connection(connectionSupplier)
                .typeConverter(new JavaToSqlTypeConverter())
                .psIndexToMethodMap(psContext.getMethods())
                .query(psContext.getQuery())
                .build();
    }

    public static <S> DataWriter<S, Integer> newIdReturningSimpleJdbcWriteR(DataSource dataSource, Supplier<Connection> connectionSupplier, Class<S> objectType){

        PreparedStatementContext preparedStatementContext = generatePsInvocationMethods(objectType, dataSource);
        if(preparedStatementContext.getIdColumns().length != 1){
            throw new IllegalArgumentException("the provided bean: '"+objectType.getName()+"' contains multiple non-ignorable fields. Can't derive the the autogenerated id");
        }

        return IdReturningSimpleJdbcWriter.<S>builder()
                .connection(connectionSupplier)
                .idColumnName(preparedStatementContext.getIdColumns()[0]).build();
    }

    private static String generateInsertQuery(List<String> columnNames, DataSource dataSource){
        //create column definition part: (col1, col2, ...)
        String sqlInsertColumnDefinition = columnNames.stream().collect(Collectors.joining(",","(",")"));
        //create parameterizable part: (?, ?, ...)
        String sqlParameterPart = columnNames.stream().map(c -> "?").collect(Collectors.joining(",","(",")"));

        return "INSERT INTO "+dataSource.getUri()+" "+sqlInsertColumnDefinition+" VALUES "+sqlParameterPart;
    }

    private static <S> PreparedStatementContext generatePsInvocationMethods(Class<S> objectType, DataSource dataSource){
        ColumnToFieldMapping<S> columnToFieldMapping = new ColumnToFieldMapping<>(objectType);

        Map<String, Field> columnFieldMap = columnToFieldMapping.getNonIgnorableFieldMappings();

        //since a prepared statement should be updated dynamically, the order of items does matter
        List<String> columnNames = new ArrayList<>(columnFieldMap.size());
        SortedMap<Integer, Method> methods = new TreeMap<>();

        Map<String, Field> fieldMap = columnFieldMap.values().stream().collect(Collectors.toMap(Field::getName, field-> field));

        try {
            PropertyDescriptor[] propertyDescriptors = Introspector.getBeanInfo(objectType).getPropertyDescriptors();

            Map<String, Method> propertyNamesToGetMethods = Arrays.stream(propertyDescriptors)
                    .filter(propertyDescriptor -> propertyDescriptor.getReadMethod() != null)
                    .filter(propertyDescriptor -> fieldMap.containsKey(propertyDescriptor.getName()))
                    .collect(Collectors.toMap(
                            PropertyDescriptor::getName,
                            PropertyDescriptor::getReadMethod
                    ));

            AtomicInteger psParameterIndex = new AtomicInteger(1);
            columnFieldMap.forEach((k,v) -> {
                columnNames.add(k);
                methods.put(psParameterIndex.getAndIncrement(), propertyNamesToGetMethods.get(v.getName()));
            });
        } catch (IntrospectionException e) {
            e.printStackTrace();
            throw new RuntimeException(e);
        }
        String query = generateInsertQuery(columnNames, dataSource);


        var ignorableFieldMappings = columnToFieldMapping.getIgnorableFieldMappings();
        Collection<String> keys = ignorableFieldMappings == null ? Collections.emptyList() : ignorableFieldMappings.keySet();
        String[] ignorableColumnNames = keys.toArray(String[]::new);

        return new PreparedStatementContext(query, methods, ignorableColumnNames);
    }
}
